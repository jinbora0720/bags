library(bags)
library(bags)
rm(list = ls())
# dependencies
library(tidyverse)
theme_set(theme_bw())
library(sf)
library(maps)
library(scales)
library(meshed)
library(INLA)
library(metR)
library(bags)
library(scico)
path <- "~/BAG_revision/"
########
# data #
########
# call data
fire <- readRDS(paste0(path, "data/CA_fire_20211028.RDS"))
data0 <- readRDS(paste0(path, "data/CA_final_20211028.RDS")) %>%
rename(time = date, logpm25 = logpm25_mean)
data0 %>% group_by(time) %>% summarise(n = n()) %>% summary()
# california map
states <- st_as_sf(map("state", plot = FALSE, fill = TRUE))
ca_sf <- st_transform(states %>% filter(ID == "california"), 26911)
ca_range <- st_bbox(ca_sf)
timelist <- unique(data0$time)
timedf <- data.frame(time = timelist, time_d = 1:length(timelist))
data <- left_join(data0, timedf, by = "time") %>%
rename(true_easting = easting, true_northing = northing) %>%
mutate(time = (time_d - min(time_d))/(max(time_d) - min(time_d)),
easting = true_easting/1000, northing = true_northing/1000) # m to km
rm(data0)
tgrid <- sort(unique(data$time))
n_time <- length(tgrid)
# train data
# fully predict the space at the last time point
prob <- 0.8
set.seed(123)
data <- data %>% group_by(easting, northing) %>%
mutate(train = ifelse(runif(1) < prob, 1, 0)) %>%
ungroup(easting, northing)
n <- nrow(data)
tr_idx <- which(data$train == 1)
n_tr <- length(tr_idx)
x_tr <- data$dist_to_fire[tr_idx]
y_tr <- data$logpm25[tr_idx]
coords_tr <- data[tr_idx, c("easting", "northing", "time",
"time_d", "true_easting", "true_northing")]
tt_idx <- which(data$train == 0)
n_tt <- length(tt_idx)
x_tt <- data$dist_to_fire[tt_idx]
y_tt <- data$logpm25[tt_idx]
coords_tt <- data[tt_idx, c("easting", "northing", "time",
"time_d", "true_easting", "true_northing")]
# prediction data
xgrid <- seq(ca_range$xmin, ca_range$xmax, length = 80)
ygrid <- seq(ca_range$ymin, ca_range$ymax, length = 100)
xygrid <- expand.grid(easting = xgrid, northing = ygrid, time_d = 1:n_time)
xygrid_sf <- st_as_sf(xygrid, coords = c("easting", "northing"), crs = 26911)
xygrid <- xygrid %>% mutate(inCA = as.numeric(st_intersects(xygrid_sf, ca_sf$geom)))
coords_grid <- xygrid %>% filter(inCA == 1) %>%
rename(true_easting = easting, true_northing = northing) %>%
mutate(easting = true_easting/1000, northing = true_northing/1000,
time = (time_d - min(time_d))/(max(time_d) - min(time_d)))
n_grid <- nrow(coords_grid)
x_grid <- rep(0, n_grid)
for (t in 1:n_time) {
idx_tmp <- which(coords_grid$time == tgrid[t])
data_tmp <- coords_grid[idx_tmp,]
fire_tmp <- fire %>% filter(date == timelist[t])
nn_tmp <- RANN::nn2(fire_tmp[,c("easting","northing")],
data_tmp[,c("true_easting","true_northing")], k=1)
x_grid[idx_tmp] <- nn_tmp$nn.dists
}
# pre-processing
# CA area
# width 890.3218km = (ca_range$xmax - ca_range$xmin)/1000
# height 1075.088km = (ca_range$ymax - ca_range$ymin)/1000
n_easting <- 16 # (~ 55km, ~0.5 degree resolution)
n_northing <- 20
easting_cut <- seq(ca_range$xmin, ca_range$xmax, length = n_easting + 1)
northing_cut <- seq(ca_range$ymin, ca_range$ymax, length = n_northing + 1)
easting_midval <- 0.5*easting_cut[1:n_easting] + 0.5*easting_cut[-1]
northing_midval <- 0.5*northing_cut[1:n_northing] + 0.5*northing_cut[-1]
###########
# Methods #
###########
# directions
directions <- c("W", "NW", "N", "NE")
mcmc <- list(save = 5, burn = 1, thin = 1)
# prior
la = lc <- 0
ua = uc <- 1000
# scaling X
x_scale <- scale(c(x_tr, x_tt, x_grid), center = T, scale = T)
X_tr <- as.matrix(x_scale[1:n_tr])
X_pred <- as.matrix(x_scale[n_tr+1:(n_tt+n_grid)])
## bdags ##
out <- bag(y = y_tr, X = X_tr,
coords = as.matrix(coords_tr[,c("easting", "northing", "time")]),
X_pred = X_pred,
coords_pred = as.matrix(rbind(coords_tt[,c("easting", "northing", "time")],
coords_grid[,c("easting", "northing", "time")])),
n_partition = c(n_easting, n_northing, n_time),
breaks_partition = list(breaks_easting = NULL,
breaks_northing = NULL,
breaks_time = NULL),
directions = directions,
init = list(tau_sq = NULL,
sig_sq = NULL,
w = NULL,
z = NULL,
psi = NULL,
Sn = NULL),
hyper = list(at = NULL, bt = NULL,
as = NULL, bs = NULL,
la = la, ua = ua,
lc = lc, uc = uc,
mu0 = NULL, invV0 = NULL),
mcmc = mcmc,
n_threads = 10,
seed = 123,
verbose = TRUE,
save_data = TRUE,
save_est = TRUE,
debug = list(psi_fixed = FALSE, z_fixed = FALSE))
out$est_time/out$est_iter
out$est_time/out$est_iter + out$pred_time/out$pred_iter
9.745*25000
9.745*25000/3600
9.745*25000/3600/24
9.745*30000/3600/24
9.745*40000/3600/24
15 + 25
9.745*30000/3600
setNumThreads()
rm(list = ls())
# dependencies
library(tidyverse)
theme_set(theme_bw())
library(meshed) # meshed_0.2.tar
library(bags)
########
# Data #
########
# specify number of grid on each axis to generate data
ngrid0 <- 193
n_time0 <- 59
xgrid0 <- seq(0, 1, length = ngrid0)
tgrid0 <- seq(0, 1, length = n_time0)
coords0 <- expand.grid(easting = xgrid0, northing = xgrid0, time = tgrid0) %>%
arrange(time, easting, northing)
n0 <- nrow(coords0)
# for a subset of data to fit
ngrid <- 25
n_time <- 30
xgrid <- seq(0, 1, length = ngrid)
tgrid <- seq(0, 1, length = n_time)
coords <- expand.grid(easting = xgrid, northing = 1-xgrid, time = tgrid) %>%
arrange(time, easting, northing)
n <- nrow(coords)
# true parameter values
a <- 5
c <- 20
kappa <- 1
sig_sq <- 150
nu <- 1.5
tau_sq <- 0.1
# assign partitions
n_easting <- 2
n_northing <- 6
# prior
tmaxdist <- max(dist(coords[,3], method = "manhattan"))
la <- (1/0.9-1)/tmaxdist # correlation = 0.9 at the maximum distance
ua <- (1/0.1-1)/tmaxdist # correlation = 0.1 at the maximum distance
spmaxdist <- max(dist(coords[,1:2]))
lc <- -log(0.95)/(0.1*spmaxdist) # correlation = 0.95 at 1/10 of the maximumal distance
uc <- -log(0.05)/(0.1*spmaxdist) # correlation = 0.05 at 1/10 of the maximumal distance
# generate seed
set.seed(123)
seedsave <- sample(10000, 100)
seedsave <- c(seedsave[51:74], 3)
s = 1
seed <- seedsave[s]
set.seed(seed)
# create w and y
data0 <- rmeshedgp(coords = coords0 %>%
rename(Var1 = easting, Var2 = northing, Var3 = time),
theta = c(a, c, kappa, sig_sq, nu),
axis_partition = c(ngrid0, 1, n_time0),
n_threads = 10) %>%
mutate(easting = Var2, northing = 1-Var1, time = Var3) %>%
select(easting, northing, time, w)
data0$y <- data0$w + sqrt(tau_sq)*rnorm(n0)
data <- inner_join(coords, data0, by = c("easting", "northing", "time"))
#################
# Training data #
#################
# train data
prob <- 0.8
grid0 <- expand.grid(easting = xgrid, northing = 1-xgrid)
idx_tr_tmp <- sort(sample(nrow(grid0), nrow(grid0)*prob))
xygrid_tr <- list()
for (tt in 1:n_time) {
xygrid_tr[[tt]] <- data.frame(grid0[idx_tr_tmp,], time = tgrid[tt])
}
xygrid_tr <- do.call(rbind, xygrid_tr) %>% arrange(easting, northing, time)
data_tr <- left_join(xygrid_tr,
data %>% mutate(idx = 1:n),
by = c("easting", "northing", "time"))
tr_idx <- data_tr$idx
n_tr <- length(tr_idx)
n_tt <- n - n_tr
w_tr <- data_tr$w
w_tt <- data$w[-tr_idx]
y_tr <- data_tr$y
y_tt <- data$y[-tr_idx]
coords_tr <- data_tr[, c("easting", "northing", "time")]
coords_tt <- data[-tr_idx, c("easting", "northing", "time")]
# directions
directions <- c("NW", "N", "NE", "E")
mcmc
# mcmc
mcmc <- list(save = 1000, burn = 5000, thin = 2)
# bag
out <- bag(y = y_tr, X = NULL,
coords = as.matrix(coords_tr[,c("easting", "northing", "time")]),
X_pred = NULL,
coords_pred = as.matrix(coords_tt[,c("easting", "northing", "time")]),
n_partition = c(n_easting, n_northing, n_time),
breaks_partition = list(breaks_easting = NULL,
breaks_northing = NULL,
breaks_time = NULL),
directions = directions,
init = list(tau_sq = NULL,
sig_sq = NULL,
w = NULL,
z = NULL,
psi = NULL,
Sn = NULL),
hyper = list(at = NULL, bt = NULL,
as = NULL, bs = NULL,
la = la, ua = ua,
lc = lc, uc = uc,
mu0 = NULL, invV0 = NULL),
mcmc = mcmc,
n_threads = 10,
seed = 123,
verbose = TRUE,
save_data = TRUE,
save_est = TRUE,
debug = list(psi_fixed = FALSE, z_fixed = FALSE))
# compare results with paper
plot(out$tau_sq_save, type = "l")
mean(out$tau_sq_save)
plot(out$sig_sq_save, type = "l")
mean(out$sig_sq_save)
coda::effectiveSize(out$tau_sq_save)
coda::effectiveSize(out$sig_sq_save)
plot(out$psi_save[1,], type = "l")
plot(out$psi_save[2,], type = "l")
plot(out$psi_save[3,], type = "l")
plot(out$psi_save[1,]*out$psi_save[3,], type = "l")
plot(out$psi_save[1,]/out$psi_save[3,], type = "l")
plot(out$sig_sq_save*out$psi_save[2,], type = "l")
plot(out$sig_sq_save, type = "l")
plot(out$sig_sq_save*out$psi_save[2,], type = "l")
coda::effectiveSize(out$sig_sq_save*out$psi_save[2,])
coda::effectiveSize(out$psi_save[1,]/out$psi_save[3,])
coda::effectiveSize(out$sig_sq_save)
coda::effectiveSize(out$psi_save[1,])
coda::effectiveSize(out$psi_save[2,])
coda::effectiveSize(out$psi_save[3,])
coda::effectiveSize(out$psi_save[1,]/out$psi_save[3,])
rbind(out$sig_sq_save, out$psi_save) %>%
t() %>%
cor()
prop <- 0.35
n_samp <- ceiling(0.25*save)
n1 = n2 <- n_samp
n_samp <- ceiling(0.25*mcmc$save)
prop <- 0.35
n_samp <- ceiling(0.25*mcmc$save)
n1 = n2 <- n_samp
ii <- sample.int(nrow(out$z_save), 1)
samp1 <- out$z_save[ii,1:n_samp]
samp2 <- out$z_save[ii,(mcmc$save - n_samp) + 1:n_samp]
N1 <- c(sum(samp1 == directions[1]), sum(samp1 == directions[2]),
sum(samp1 == directions[3]), sum(samp1 == directions[4]))
p1 <- N1/n1
N2 <- c(sum(samp2 == directions[1]), sum(samp2 == directions[2]),
sum(samp2 == directions[3]), sum(samp2 == directions[4]))
p2 <- N2/n2
p <- (N1 + N2)/(n1 + n2)
R <- which(p != 0)
nR <- sum(p != 0)
X_sq <- n1*sum((p1[R] - p[R])^2/p[R]) + n2*sum((p2[R] - p[R])^2/p[R])
R
(pvalue <- pchisq(X_sq, df = (nR-1)*(2-1), lower.tail = FALSE))
table(out$z_save)
# compare results with paper
out$est_time/out$est_iter + out$pred_time/out$est_iter
(out$est_time/out$est_iter + out$pred_time/out$est_iter)[1:3]
as.numeric(out$est_time/out$est_iter +
out$pred_time/out$est_iter)[1:3]
# prediction summary
y_bdag <- rowMeans(out$y_pred_save)
y_bdag_qt <- apply(out$y_pred_save, 1, function(x) quantile(x, probs = c(0.025, 0.975)))
y_bdag_low <- y_bdag_qt[1,]
y_bdag_hi <- y_bdag_qt[2,]
mean(ifelse(y_tt > y_bdag_low & y_tt < y_bdag_hi, 1, 0))
mean(y_bdag_hi - y_bdag_low)
sqrt(mean((y_tt-y_bdag)^2))
mean(abs(y_tt-y_bdag))
tmp <- readRDS("~/BAG/sim2/bdags_sim2l_bdaggp.RDS")
tmp$rmspe
tmp$mape
mean(out$tau_sq_save)
rowMeans(out$psi_save)
mean(out$sig_sq_save)
out$z_save
names(out)
# effective sample size
nrow(out$y_pred_save)
# effective sample size
apply(out$y_pred_save, 1, coda::effectiveSize)
# effective sample size
y_pred_ess <- apply(out$y_pred_save, 1, coda::effectiveSize)
summary(y_pred_ess)
data0$timename <- paste0("time = ",round(data0$time,3))
n_time0 <- 59
tgrid0 <- seq(0, 1, length = n_time0)
plot1 <- data0 %>%
filter(time > tgrid0[11] & time <= tgrid0[16]) %>%
ggplot() +
geom_raster(aes(easting, northing, fill = w)) +
geom_contour(aes(easting, northing, z = w), breaks=2.5, color="black") +
scale_x_continuous(breaks=c(0, .5, 1)) +
scale_y_continuous(breaks=c(0, .5, 1)) +
scale_fill_viridis_c() +
theme(plot.margin=margin(t=2,l=-2, r=2, b=-5),
legend.margin=margin(b=0,r=0,t=0,l=-6)) +
facet_wrap(~timename, nrow = 1) +
labs(x="", y="")
plot1
warnings()
tmp$rmspe
tmp$mape
sqrt(mean((y_tt-y_bdag)^2))
mean(abs(y_tt-y_bdag))
mean(y_pred_ess)
coda::effectiveSize(out$tau_sq_save)
apply(out$psi_save, 1, coda::effectiveSize)
coda::effectiveSize(out$sig_sq_save)
rmspe = mape = coverage = meanwidth = tausq_hat = sigsq_hat <- rep(0, 25)
psi_hat = time_per_iter <- matrix(0, nrow = 3, ncol = 25)
z_pvalue = z_save = y_pred_ess <- list()
# time spent per iteration
time_per_iter[,s] <- as.numeric(out$est_time/out$est_iter +
out$pred_time/out$est_iter)[1:3]
time_per_iter
# parameter estimation summary
tausq_hat[s] <- mean(out$tau_sq_save)
psi_hat[,s] <- rowMeans(out$psi_save)
sigsq_hat[s] <- mean(out$sig_sq_save)
z_save[[s]] <- out$z_save
tausq_hat
psi_hat
sigsq_hat
z_save
# effective sample size
y_pred_ess[[s]] <- apply(out$y_pred_save, 1, coda::effectiveSize)
y_pred_ess[[s]]
pvalue <- rep(0, nrow(out$z_save))
for (ii in 1:nrow(out$z_save)) {
samp1 <- out$z_save[ii,1:n_samp]
samp2 <- out$z_save[ii,(mcmc$save - n_samp) + 1:n_samp]
N1 <- c(sum(samp1 == directions[1]), sum(samp1 == directions[2]),
sum(samp1 == directions[3]), sum(samp1 == directions[4]))
p1 <- N1/n1
N2 <- c(sum(samp2 == directions[1]), sum(samp2 == directions[2]),
sum(samp2 == directions[3]), sum(samp2 == directions[4]))
p2 <- N2/n2
p <- (N1 + N2)/(n1 + n2)
R <- which(p != 0)
nR <- sum(p != 0)
X_sq <- n1*sum((p1[R] - p[R])^2/p[R]) + n2*sum((p2[R] - p[R])^2/p[R])
pvalue[ii] <- pchisq(X_sq, df = (nR-1)*(2-1), lower.tail = FALSE)
}
pvalue
z_pvalue[[s]] <- pvalue
# prediction summary
y_bdag <- rowMeans(out$y_pred_save)
y_bdag_qt <- apply(out$y_pred_save, 1, function(x) quantile(x, probs = c(0.025, 0.975)))
y_bdag_low <- y_bdag_qt[1,]
y_bdag_hi <- y_bdag_qt[2,]
coverage[s] <- mean(ifelse(y_tt > y_bdag_low & y_tt < y_bdag_hi, 1, 0))
meanwidth[s] <- mean(y_bdag_hi - y_bdag_low)
rmspe[s] <- sqrt(mean((y_tt-y_bdag)^2))
mape[s] <- mean(abs(y_tt-y_bdag))
coverage
meanwidth
rmspe
mape
path
########
# Data #
########
# specify number of grid on each axis to generate data
ngrid0 <- 193
# path
path <- "~/BAG_revision/"
paste0(path, "sim2/sim2a_bag.RDS")
cat(s, "th iteration completed.")
seed
sessionInfo()
?bags
library(bags)
