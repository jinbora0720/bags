rm(list = ls())

# dependencies 
library(tidyverse)
theme_set(theme_bw())
library(sf)
library(maps)
library(scales)
library(meshed)
library(INLA)
library(metR)

########
# data #
########
# source code 
path <- "~/BAG_revision/"
source(paste0(path, "scr/bag.R"))
source(paste0(path, "scr/bag_utils.R"))
Rcpp::sourceCpp(paste0(path, 'scr/bag_source.cpp'))
Rcpp::sourceCpp(paste0(path, 'scr/bag_predict.cpp'))

# call data
fire <- readRDS("~/BAG/data/CA_fire_20211028.RDS")
data0 <- readRDS("~/BAG/data/CA_final_20211028.RDS") %>% 
  rename(time = date, logpm25 = logpm25_mean)
data0 %>% group_by(time) %>% summarise(n = n()) %>% summary()

# california map
states <- st_as_sf(map("state", plot = FALSE, fill = TRUE))
ca_sf <- st_transform(states %>% filter(ID == "california"), 26911)
ca_range <- st_bbox(ca_sf)

timelist <- unique(data0$time)
timedf <- data.frame(time = timelist, time_d = 1:length(timelist))
data <- left_join(data0, timedf, by = "time") %>% 
  rename(true_easting = easting, true_northing = northing) %>% 
  mutate(time = (time_d - min(time_d))/(max(time_d) - min(time_d)), 
         easting = true_easting/1000, northing = true_northing/1000) # m to km 
rm(data0)
tgrid <- sort(unique(data$time))
n_time <- length(tgrid)

# train data
# fully predict the space at the last time point 
prob <- 0.8
set.seed(123)
data <- data %>% group_by(easting, northing) %>% 
  mutate(train = ifelse(runif(1) < prob, 1, 0)) %>% 
  ungroup(easting, northing)
n <- nrow(data)

tr_idx <- which(data$train == 1)
n_tr <- length(tr_idx)
x_tr <- data$dist_to_fire[tr_idx]
y_tr <- data$logpm25[tr_idx]
coords_tr <- data[tr_idx, c("easting", "northing", "time", 
                            "time_d", "true_easting", "true_northing")] 

tt_idx <- which(data$train == 0)
n_tt <- length(tt_idx)
x_tt <- data$dist_to_fire[tt_idx]
y_tt <- data$logpm25[tt_idx]
coords_tt <- data[tt_idx, c("easting", "northing", "time", 
                            "time_d", "true_easting", "true_northing")] 

# prediction data
xgrid <- seq(ca_range$xmin, ca_range$xmax, length = 80)
ygrid <- seq(ca_range$ymin, ca_range$ymax, length = 100)
xygrid <- expand.grid(easting = xgrid, northing = ygrid, time_d = 1:n_time)
xygrid_sf <- st_as_sf(xygrid, coords = c("easting", "northing"), crs = 26911)
xygrid <- xygrid %>% mutate(inCA = as.numeric(st_intersects(xygrid_sf, ca_sf$geom)))

coords_grid <- xygrid %>% filter(inCA == 1) %>% 
  rename(true_easting = easting, true_northing = northing) %>% 
  mutate(easting = true_easting/1000, northing = true_northing/1000, 
         time = (time_d - min(time_d))/(max(time_d) - min(time_d)))
n_grid <- nrow(coords_grid)
x_grid <- rep(0, n_grid)
for (t in 1:n_time) {
  idx_tmp <- which(coords_grid$time == tgrid[t])
  data_tmp <- coords_grid[idx_tmp,]
  fire_tmp <- fire %>% filter(date == timelist[t])
  nn_tmp <- RANN::nn2(fire_tmp[,c("easting","northing")], 
                      data_tmp[,c("true_easting","true_northing")], k=1)
  x_grid[idx_tmp] <- nn_tmp$nn.dists
}

# pre-processing
# CA area
# width 890.3218km = (ca_range$xmax - ca_range$xmin)/1000
# height 1075.088km = (ca_range$ymax - ca_range$ymin)/1000
n_easting <- 16 # (~ 55km, ~0.5 degree resolution)
n_northing <- 20
coords_ptt <- rbind(coords_tr[,c("easting", "northing", "time", "time_d")],
                    coords_tt[,c("easting", "northing", "time", "time_d")],
                    coords_grid[,c("easting", "northing", "time", "time_d")])
###########
# Methods #
###########
# prior
la = lc <- 0
ua = uc <- 1000

# scaling X
x_scale <- scale(c(x_tr, x_tt, x_grid), center = T, scale = T)
X_tr <- as.matrix(x_scale[1:n_tr])
X_pred <- as.matrix(x_scale[n_tr+1:(n_tt+n_grid)])

# centering
ybar <- mean(y_tr)

## mgp1 ##
mcmc <- list(save=1000, burn=15000, thin=50)

# set.seed(123)
# meshout <- spmeshed(family=c("gaussian"),
#                     y = c(y_tr, rep(NA, n_tt + n_grid)), x = x_scale,
#                     coords = as.matrix(coords_ptt[,c("easting", "northing", "time")]),
#                     k = 1,
#                     axis_partition = c(n_easting, n_northing, n_time),
#                     prior = list(phi = c(min(lc,la), max(uc,ua))),
#                     settings = list(adapting=TRUE, forced_grid=NULL,
#                                     cache=NULL, ps=TRUE, saving=TRUE),
#                     starting = list(beta=NULL, tausq=NULL, theta=NULL,
#                                     lambda=matrix(1,1,1), w=NULL,
#                                     nu = NULL, mcmcsd=.05, mcmc_startfrom=0),
#                     debug = list(sample_beta=TRUE, sample_tausq=TRUE,
#                                  sample_theta=TRUE, sample_w=TRUE, sample_lambda=FALSE,
#                                  verbose=TRUE, debug=FALSE),
#                     n_samples = mcmc$save, n_burn = mcmc$burn, n_thin = mcmc$thin,
#                     verbose = 100,
#                     n_threads = 10)
# saveRDS(meshout,
#         "~/BAG_revision/analysis/CA_daily_mgp.RDS")

# diagnostics
p <- 1
alpha <- 0.05 # 1-alpha: credible level
eps <- 0.1 # half the width (in eps*100%) of the desired credible interval
cutoff <- 2^(2/p)*pi*qchisq(p = 1-alpha, df = p)/(eps*(p*gamma(p/2))^(2/p))
cat("We need at least", ceiling(cutoff),
    "effective sample size so that the 95% credible interval of (independent)
    individual parameter to have a half width no greater than", eps*100, "%.")

meshout <- readRDS("~/BAG_revision/analysis/CA_daily_mgp.RDS")
mgp <- list(coordsdata = meshout$coordsdata,
            yhat_mcmc = meshout$yhat_mcmc,
            beta_mcmc = meshout$beta_mcmc[,,mcmc$thin*(1:mcmc$save)],
            tausq_mcmc = meshout$tausq_mcmc[,mcmc$thin*(1:mcmc$save)],
            psi_mcmc = meshout$theta_mcmc[-4,,mcmc$thin*(1:mcmc$save)],
            sigsq_mcmc = meshout$theta_mcmc[4,,mcmc$thin*(1:mcmc$save)])

hist(mgp$beta_mcmc)
plot(mgp$beta_mcmc, type = "l")
coda::effectiveSize(mgp$beta_mcmc)
ess(mgp$beta_mcmc)
plot(cumsum(mgp$beta_mcmc)/(1:mcmc$save), type = "l")
mean(mgp$beta_mcmc)
quantile(mgp$beta_mcmc, probs = c(0.025, 0.975))

# burn and thin
thin <- 100
save <- 500
samp_idx <- thin*1:save

plot(meshout$beta_mcmc[,,samp_idx], type = "l")
coda::effectiveSize(meshout$beta_mcmc[,,samp_idx])
ess(meshout$beta_mcmc[,,samp_idx])
plot(cumsum(meshout$beta_mcmc[,,samp_idx])/(1:save), type = "l")
